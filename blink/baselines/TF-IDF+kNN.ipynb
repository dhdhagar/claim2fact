{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d98025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import f1_score\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dca4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(x):\n",
    "    punctuations = list(string.punctuation)\n",
    "    punctuations.append('“')\n",
    "    punctuations.append('”')\n",
    "    punctuations.append(\"—\")\n",
    "    x_char = list(x)\n",
    "    for i in range(len(x_char)):\n",
    "        if x_char[i] in punctuations:\n",
    "            x_char[i]=' '\n",
    "    return ''.join(x_char)\n",
    "\n",
    "def preprocess(X):\n",
    "    X = X.str.lower()\n",
    "    stop = stopwords.words('english')\n",
    "    X = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    '''punctuations = list(string.punctuations)\n",
    "    X = X.apply(lambda x: ''.join([word for word in list(x) if word not in (punctuations)]))\n",
    "    '''\n",
    "    X=X.apply(remove_punctuations)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    X = X.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    return X\n",
    "\n",
    "def get_tf_idf_vector(X):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_tf_idf_vector = vectorizer.fit_transform(X)\n",
    "    return vectorizer, X_tf_idf_vector\n",
    "\n",
    "def get_tf_idf_vector_test(X,vectorizer):\n",
    "    return vectorizer.transform(X)\n",
    "\n",
    "def truncated_svd_on_tf_idf_vector(X):\n",
    "    truncatedSVD = TruncatedSVD(n_components=1000,n_iter=7, random_state=42)\n",
    "    X= truncatedSVD.fit_transform(X)\n",
    "    return truncatedSVD, X\n",
    "\n",
    "def truncated_svd_on_tf_idf_vector_test(X, truncatedSVD):\n",
    "    return truncatedSVD.fit_transform(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05c79c",
   "metadata": {},
   "source": [
    "## Using processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0efb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/dictionary.pickle','rb') as f:\n",
    "    dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9198df",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.DataFrame.from_dict(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b962f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_of_dict(filename):\n",
    "    train=[]\n",
    "    with open('./data/processed/'+filename,'r') as f:\n",
    "        for line in f:\n",
    "            train.append(json.loads(line))\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ae5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = return_list_of_dict('train.jsonl')\n",
    "val = return_list_of_dict('valid.jsonl')\n",
    "test = return_list_of_dict('test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a316d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(train)\n",
    "val_df = pd.DataFrame.from_dict(val)\n",
    "test_df = pd.DataFrame.from_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f2131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>mention_id</th>\n",
       "      <th>context_left</th>\n",
       "      <th>context_right</th>\n",
       "      <th>context_doc_id</th>\n",
       "      <th>type</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The families of these four should sit in the f...</td>\n",
       "      <td>780136889441456128</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>272</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user person didnt lower my my taxes and he rai...</td>\n",
       "      <td>913075551212011520</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>273</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaredBerry316 glennbeck like when white Christ...</td>\n",
       "      <td>753045148775440384</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>274</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdamKazda 60 diplomats were killed on Bushs wa...</td>\n",
       "      <td>743830161393520640</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fight4women Wow you got a source for all that ...</td>\n",
       "      <td>818188352314900480</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>275</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             mention          mention_id  \\\n",
       "0  The families of these four should sit in the f...  780136889441456128   \n",
       "1  user person didnt lower my my taxes and he rai...  913075551212011520   \n",
       "2  JaredBerry316 glennbeck like when white Christ...  753045148775440384   \n",
       "3  AdamKazda 60 diplomats were killed on Bushs wa...  743830161393520640   \n",
       "4  fight4women Wow you got a source for all that ...  818188352314900480   \n",
       "\n",
       "  context_left context_right context_doc_id type label_id label label_title  \n",
       "0                                                     272                    \n",
       "1                                                     273                    \n",
       "2                                                     274                    \n",
       "3                                                      14                    \n",
       "4                                                     275                    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd57fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['mention']\n",
    "X_val = val_df['mention']\n",
    "X_test = test_df['mention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b718a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label_id']\n",
    "y_val = val_df['label_id']\n",
    "y_test = test_df['label_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e68ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_article_df = train_df.merge(article_df,left_on='label_id', right_on='cui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5e1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_articles_in_train = train_article_df[['cui', 'title', 'description','summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa40abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_articles_in_train = only_articles_in_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce00966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_strings(df, col1, col2):\n",
    "    return_val = []\n",
    "    for i in range(len(df)):\n",
    "        return_val.append(df[col1].iloc[i]+df[col2].iloc[i])\n",
    "    return return_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded34fd",
   "metadata": {},
   "source": [
    "## Classification using full length articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8adcee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tweets = train_df['mention']\n",
    "X_train_articles = pd.Series(add_column_strings(only_articles_in_train, 'title', 'description'))\n",
    "frames = [X_train_tweets, X_train_articles]\n",
    "X_train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df9e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(X_train)\n",
    "X_test = preprocess(X_test)\n",
    "X_val = preprocess(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a7ea3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing PCA here using truncated SVD as PCA does not work for sparse matrices\n",
    "vectorizer, X_train_tf_idf_vector = get_tf_idf_vector(X_train)\n",
    "#truncatedSVD, X_train_svd = truncated_svd_on_tf_idf_vector(X_train_tf_idf_vector)\n",
    "\n",
    "X_val_tf_idf_vector = get_tf_idf_vector_test(X_val,vectorizer)\n",
    "#X_val_svd = truncated_svd_on_tf_idf_vector_test(X_val_tf_idf_vector,truncatedSVD)\n",
    "\n",
    "X_test_tf_idf_vector = get_tf_idf_vector_test(X_test,vectorizer)\n",
    "#X_test_svd = truncated_svd_on_tf_idf_vector_test(X_test_tf_idf_vector, truncatedSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1536cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_tf_idf = X_train_tf_idf_vector[-3100:]\n",
    "article_labels = only_articles_in_train['cui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e5626b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3100, 76693)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27b8da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 12.053056516724336\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0 \n",
    "correctly_classified=[]\n",
    "incorrectly_classified=[]\n",
    "incorrectly_predicted_label=[]\n",
    "y_pred_lst=[]\n",
    "for i in range(X_test_tf_idf_vector.shape[0]):\n",
    "    dot_product = np.dot(X_test_tf_idf_vector[i], article_tf_idf.T)\n",
    "    argmax = np.argmax(dot_product)\n",
    "    y_pred = article_labels.iloc[argmax]\n",
    "    y_pred_lst.append(y_pred)\n",
    "    if y_test[i] == y_pred:\n",
    "        correct+=1\n",
    "        correctly_classified.append(test_df.iloc[i])\n",
    "    else:\n",
    "        incorrectly_classified.append(test_df.iloc[i])\n",
    "        incorrectly_predicted_label.append(y_pred)\n",
    "    total+=1\n",
    "print(\"Accuracy=\",correct*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4355df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12053056516724336"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(list(y_test),y_pred_lst, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc1d976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07625551929210807"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(list(y_test),y_pred_lst, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afdd404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_eval_full_articles(correctly_classified, incorrectly_classified, incorrectly_predicted_label):\n",
    "    correctly_classified_df = pd.DataFrame(correctly_classified)\n",
    "    correctly_classified_df = correctly_classified_df.merge(article_df,left_on='label_id', right_on='cui')\n",
    "    correctly_classified_df=correctly_classified_df.drop(['context_left','context_right','context_doc_id','type','label','label_title','summary'],axis=1)\n",
    "    \n",
    "    incorrectly_classified_df = pd.DataFrame(incorrectly_classified)\n",
    "    incorrectly_classified_df['pred_label'] = incorrectly_predicted_label\n",
    "    incorrectly_classified_df = incorrectly_classified_df.merge(article_df,left_on='label_id', right_on='cui')\n",
    "    incorrect_pred = pd.DataFrame(incorrectly_predicted_label,columns=['label_id']).merge(article_df,left_on='label_id', right_on='cui')\n",
    "    print(incorrect_pred.head())\n",
    "    print(incorrectly_classified_df.shape)\n",
    "    incorrectly_classified_df = incorrectly_classified_df.merge(incorrect_pred.drop_duplicates(),how='left',left_on='pred_label', right_on='label_id')\n",
    "    print(incorrectly_classified_df.shape)\n",
    "    incorrectly_classified_df = incorrectly_classified_df.drop(['context_left','context_right','context_doc_id','type','label','label_title','cui_x','label_id_y','cui_y','summary_x','summary_y'],axis=1)\n",
    "    incorrectly_classified_df= incorrectly_classified_df.rename(columns={\"label_id_x\":\"true_label\",\"title_x\":\"true_title\",\"description_x\":\"true_description\",\"title_y\":\"pred_title\",\"description_y\":\"pred_description\"})\n",
    "    return correctly_classified_df, incorrectly_classified_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c17e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label_id  cui                                        title description  \\\n",
      "0      183  183  Gun Deaths vs Baseball Bat Deaths Snopescom               \n",
      "1      183  183  Gun Deaths vs Baseball Bat Deaths Snopescom               \n",
      "2      183  183  Gun Deaths vs Baseball Bat Deaths Snopescom               \n",
      "3      183  183  Gun Deaths vs Baseball Bat Deaths Snopescom               \n",
      "4      183  183  Gun Deaths vs Baseball Bat Deaths Snopescom               \n",
      "\n",
      "  summary  \n",
      "0          \n",
      "1          \n",
      "2          \n",
      "3          \n",
      "4          \n",
      "(4575, 14)\n",
      "(4575, 19)\n"
     ]
    }
   ],
   "source": [
    "correctly_classified_df, incorrectly_classified_df=error_eval_full_articles(correctly_classified, incorrectly_classified, incorrectly_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bc31762",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_classified_df.to_csv('TF-IDF_kNN_IncorrectPredictionsUsingFullArticles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcb059d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified_df.to_csv('TF-IDF_kNN_CorrectPredictionsUsingFullArticles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9531e",
   "metadata": {},
   "source": [
    "## Classification using summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87821455",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tweets = train_df['mention']\n",
    "X_train_articles = pd.Series(add_column_strings(only_articles_in_train, 'title', 'summary'))\n",
    "frames = [X_train_tweets, X_train_articles]\n",
    "X_train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12953ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(X_train)\n",
    "X_test = preprocess(X_test)\n",
    "X_val = preprocess(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d895635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing PCA here using truncated SVD as PCA does not work for sparse matrices\n",
    "vectorizer, X_train_tf_idf_vector = get_tf_idf_vector(X_train)\n",
    "#truncatedSVD, X_train_svd = truncated_svd_on_tf_idf_vector(X_train_tf_idf_vector)\n",
    "\n",
    "X_val_tf_idf_vector = get_tf_idf_vector_test(X_val,vectorizer)\n",
    "#X_val_svd = truncated_svd_on_tf_idf_vector_test(X_val_tf_idf_vector,truncatedSVD)\n",
    "\n",
    "X_test_tf_idf_vector = get_tf_idf_vector_test(X_test,vectorizer)\n",
    "#X_test_svd = truncated_svd_on_tf_idf_vector_test(X_test_tf_idf_vector, truncatedSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d28b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tf_idf = X_train_tf_idf_vector[-3100:]\n",
    "summary_labels = only_articles_in_train['cui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40bb15be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random accuracy= 0.0\n",
      "Real accuracy= 12.245290272971934\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0 \n",
    "correct_random = 0\n",
    "correctly_classified=[]\n",
    "incorrectly_classified=[]\n",
    "incorrectly_predicted_label=[]\n",
    "y_pred_lst=[]\n",
    "for i in range(X_test_tf_idf_vector.shape[0]):\n",
    "    dot_product = np.dot(X_test_tf_idf_vector[i], summary_tf_idf.T)\n",
    "    argmax = np.argmax(dot_product)\n",
    "    y_pred = summary_labels.iloc[argmax]\n",
    "    random_argmax = random.randint(0,3099)\n",
    "    y_pred_random = summary_labels.iloc[random_argmax]\n",
    "    y_pred_lst.append(y_pred)\n",
    "    if y_test[i] == y_pred:\n",
    "        correct+=1\n",
    "        correctly_classified.append(test_df.iloc[i])\n",
    "    else:\n",
    "        incorrectly_classified.append(test_df.iloc[i])\n",
    "        incorrectly_predicted_label.append(y_pred)\n",
    "    if y_test[i] == y_pred_random:\n",
    "        correct_random +=1\n",
    "    total+=1\n",
    "print(\"Random accuracy=\",correct_random*100/total)\n",
    "print(\"Real accuracy=\",correct*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9b9d1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12245290272971934"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(list(y_test),y_pred_lst, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f157ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07512497365764031"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(list(y_test),y_pred_lst, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3bce28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_eval_summary(correctly_classified, incorrectly_classified, incorrectly_predicted_label):\n",
    "    correctly_classified_df = pd.DataFrame(correctly_classified)\n",
    "    correctly_classified_df = correctly_classified_df.merge(article_df,left_on='label_id', right_on='cui')\n",
    "    correctly_classified_df=correctly_classified_df.drop(['context_left','context_right','context_doc_id','type','label','label_title','description'],axis=1)\n",
    "    \n",
    "    incorrectly_classified_df = pd.DataFrame(incorrectly_classified)\n",
    "    incorrectly_classified_df['pred_label'] = incorrectly_predicted_label\n",
    "    incorrectly_classified_df = incorrectly_classified_df.merge(article_df,left_on='label_id', right_on='cui')\n",
    "    incorrect_pred = pd.DataFrame(incorrectly_predicted_label,columns=['label_id']).merge(article_df,left_on='label_id', right_on='cui')\n",
    "    incorrectly_classified_df = incorrectly_classified_df.merge(incorrect_pred.drop_duplicates(),left_on='pred_label', right_on='cui')\n",
    "    incorrectly_classified_df = incorrectly_classified_df.drop(['context_left','context_right','context_doc_id','type','label','label_title','cui_x','label_id_y','cui_y','description_x','description_y'],axis=1)\n",
    "    incorrectly_classified_df= incorrectly_classified_df.rename(columns={\"label_id_x\":\"true_label\",\"title_x\":\"true_title\",\"summary_x\":\"true_summary\",\"title_y\":\"pred_title\",\"summary_y\":\"pred_summary\"})\n",
    "    return correctly_classified_df, incorrectly_classified_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b50f5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    " correctly_classified_df, incorrectly_classified_df = error_eval_summary(correctly_classified, incorrectly_classified, incorrectly_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00bfd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_classified_df.to_csv('TF-IDF_kNN_IncorrectPredictionsUsingSummaries.csv')\n",
    "correctly_classified_df.to_csv('TF-IDF_kNN_CorrectPredictionsUsingSummaries.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
